{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from FrEIA.framework import InputNode, OutputNode, Node, ReversibleGraphNet\n",
    "from FrEIA.modules import GLOWCouplingBlock, PermuteRandom\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 100\n",
    "\n",
    "img = torch.from_numpy(np.load(\"dataImagesPCA.npy\").reshape(900,-1)).float()\n",
    "boundary = torch.from_numpy(np.load(\"dataBoundary.npy\")).float()\n",
    "print(img.shape, boundary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim_x = 900\n",
    "ndim_y = 256\n",
    "ndim_z = 500\n",
    "ndim_tot = ndim_x + ndim_y + ndim_z\n",
    "\n",
    "def subnet_fc(c_in, c_out):\n",
    "    return nn.Sequential(nn.Linear(c_in, 80),nn.ReLU(),\n",
    "                         nn.Linear(80,  c_out))\n",
    "def subnet_conv(c_in, c_out):\n",
    "    return nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=1)\n",
    "\n",
    "nodes = [InputNode(ndim_tot, name='input')]\n",
    "\n",
    "for k in range(4):\n",
    "    nodes.append(Node(nodes[-1],\n",
    "                      GLOWCouplingBlock,\n",
    "                      {'subnet_constructor':subnet_fc, 'clamp':2.0},\n",
    "                      name=F'coupling_{k}'))\n",
    "    nodes.append(Node(nodes[-1],\n",
    "                      PermuteRandom,\n",
    "                      {'seed':k},\n",
    "                      name=F'permute_{k}'))\n",
    "\n",
    "nodes.append(OutputNode(nodes[-1], name='output'))\n",
    "\n",
    "model = ReversibleGraphNet(nodes, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_epochs = 500\n",
    "n_its_per_epoch = 2\n",
    "batch_size = 640\n",
    "\n",
    "lr = 1e-3\n",
    "l2_reg = 2e-5\n",
    "\n",
    "y_noise_scale = 1e-1\n",
    "zeros_noise_scale = 5e-2\n",
    "\n",
    "# relative weighting of losses:\n",
    "lambd_predict = 3.\n",
    "lambd_latent = 300.\n",
    "lambd_rev = 400.\n",
    "\n",
    "pad_x = torch.zeros(batch_size, ndim_tot - ndim_x)\n",
    "pad_yz = torch.zeros(batch_size, ndim_tot - ndim_y - ndim_z)\n",
    "\n",
    "trainable_parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(trainable_parameters, lr=lr, betas=(0.8, 0.9),\n",
    "                             eps=1e-6, weight_decay=l2_reg)\n",
    "\n",
    "\n",
    "def MMD_multiscale(x, y):\n",
    "    xx, yy, zz = torch.mm(x,x.t()), torch.mm(y,y.t()), torch.mm(x,y.t())\n",
    "\n",
    "    rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
    "    ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
    "\n",
    "    dxx = rx.t() + rx - 2.*xx\n",
    "    dyy = ry.t() + ry - 2.*yy\n",
    "    dxy = rx.t() + ry - 2.*zz\n",
    "\n",
    "    XX, YY, XY = (torch.zeros(xx.shape).to(device),\n",
    "                  torch.zeros(xx.shape).to(device),\n",
    "                  torch.zeros(xx.shape).to(device))\n",
    "\n",
    "    for a in [0.05, 0.2, 0.9]:\n",
    "        XX += a**2 * (a**2 + dxx)**-1\n",
    "        YY += a**2 * (a**2 + dyy)**-1\n",
    "        XY += a**2 * (a**2 + dxy)**-1\n",
    "\n",
    "    return torch.mean(XX + YY - 2.*XY)\n",
    "\n",
    "\n",
    "def fit(input, target):\n",
    "    return torch.mean((input - target)**2)\n",
    "\n",
    "loss_backward = MMD_multiscale\n",
    "loss_latent = MMD_multiscale\n",
    "loss_fit = fit\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(img[:test_split], boundary[:test_split]),\n",
    "    batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(img[test_split:], boundary[test_split:]),\n",
    "    batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(i_epoch=0):\n",
    "    model.train()\n",
    "\n",
    "    l_tot = 0\n",
    "    batch_idx = 0\n",
    "    \n",
    "    t_start = time()\n",
    "    \n",
    "    # If MMD on x-space is present from the start, the model can get stuck.\n",
    "    # Instead, ramp it up exponetially.  \n",
    "    loss_factor = min(1., 2. * 0.002**(1. - (float(i_epoch) / n_epochs)))\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        batch_idx += 1\n",
    "        if batch_idx > n_its_per_epoch:\n",
    "            break\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        y_clean = y.clone()\n",
    "        pad_x = zeros_noise_scale * torch.randn(batch_size, ndim_tot -\n",
    "                                                ndim_x, device=device)\n",
    "        pad_yz = zeros_noise_scale * torch.randn(batch_size, ndim_tot -\n",
    "                                                 ndim_y - ndim_z, device=device)\n",
    "\n",
    "        y += y_noise_scale * torch.randn(batch_size, ndim_y, dtype=torch.float, device=device)\n",
    "\n",
    "        x, y = (torch.cat((x, pad_x),  dim=1),\n",
    "                torch.cat((torch.randn(batch_size, ndim_z, device=device), pad_yz, y),\n",
    "                          dim=1))\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward step:\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        # Shorten output, and remove gradients wrt y, for latent loss\n",
    "        y_short = torch.cat((y[:, :ndim_z], y[:, -ndim_y:]), dim=1) # remove rand padding\n",
    "\n",
    "        l = lambd_predict * loss_fit(output[:, ndim_z:], y[:, ndim_z:]) # apply loss fit on y\n",
    "\n",
    "        output_block_grad = torch.cat((output[:, :ndim_z],           # remove rand, same shape as y_short\n",
    "                                       output[:, -ndim_y:].data), dim=1)\n",
    "\n",
    "        l += lambd_latent * loss_latent(output_block_grad, y_short) # apply Latent Loss on latent output and output y\n",
    "        l_tot += l.data.item()\n",
    "\n",
    "        # l is for z latent loss and y prediction loss\n",
    "        l.backward()\n",
    "\n",
    "        # Backward step:\n",
    "        pad_yz = zeros_noise_scale * torch.randn(batch_size, ndim_tot -\n",
    "                                                 ndim_y - ndim_z, device=device)\n",
    "        y = y_clean + y_noise_scale * torch.randn(batch_size, ndim_y, device=device)\n",
    "\n",
    "        orig_z_perturbed = (output.data[:, :ndim_z] + y_noise_scale *\n",
    "                            torch.randn(batch_size, ndim_z, device=device))\n",
    "        y_rev = torch.cat((orig_z_perturbed, pad_yz,\n",
    "                           y), dim=1)\n",
    "        y_rev_rand = torch.cat((torch.randn(batch_size, ndim_z, device=device), pad_yz,\n",
    "                                y), dim=1)\n",
    "        \n",
    "        output_rev = model(y_rev, rev=True)\n",
    "        output_rev_rand = model(y_rev_rand, rev=True)\n",
    "\n",
    "        l_rev = (\n",
    "            lambd_rev\n",
    "            * loss_factor\n",
    "            * loss_backward(output_rev_rand[:, :ndim_x],\n",
    "                            x[:, :ndim_x]) #  apply loss backward on recovered x and real x\n",
    "        )\n",
    "\n",
    "        l_rev += lambd_predict * loss_fit(output_rev, x) # apply loss fit on recovered x and real x\n",
    "        \n",
    "        l_tot += l_rev.data.item()\n",
    "        l_rev.backward()\n",
    "\n",
    "        for p in model.parameters():\n",
    "            p.grad.data.clamp_(-15.00, 15.00)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    return l_tot / batch_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_samps):\n",
    "    return model(torch.cat((x_samps, torch.zeros(N_samp, ndim_tot - ndim_x)),\n",
    "                                 dim=1).to(device))[:,-ndim_y:]\n",
    "def error(y1,y2):\n",
    "    return torch.mean((y1**2-y2**2)/y2**2)/len(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in trainable_parameters:\n",
    "    param.data = 0.05*torch.randn_like(param)\n",
    "            \n",
    "model.to(device)\n",
    "  \n",
    "try:\n",
    "    t_start = time()\n",
    "    for i_epoch in range(n_epochs):\n",
    "        print(\"Epoch:\",i_epoch,\"Loss:\",train(i_epoch))   \n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    print(f\"\\n\\nTraining took {(time()-t_start)/60:.2f} minutes\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_samp = 100\n",
    "\n",
    "x_samps = img[:N_samp]\n",
    "y_samps = boundary[:N_samp]\n",
    "print(x_samps.shape,y_samps.shape)\n",
    "y_samps += y_noise_scale * torch.randn(N_samp, ndim_y)\n",
    "y_samps = torch.cat([torch.randn(N_samp, ndim_z),\n",
    "                     zeros_noise_scale * torch.zeros(N_samp, ndim_tot - ndim_y - ndim_z), \n",
    "                     y_samps], dim=1)\n",
    "y_samps = y_samps.to(device)\n",
    "y_p=predict(x_samps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"error of forward prediction:\",error(y_p,y_samps[:,-ndim_y:]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "with open(\"pca.pkl\",\"rb\") as f:\n",
    "    pca = pk.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 4\n",
    "sample_boundary = y_samps[sample_index:sample_index+1,:]\n",
    "sample_img = x_samps[sample_index:sample_index+1,:].detach().numpy()\n",
    "recovered_img = model(sample_boundary,rev=True)[:,:ndim_x].cpu().detach().numpy()\n",
    "print(recovered_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,axs = plt.subplots(1,2)\n",
    "axs[0].imshow(pca.inverse_transform(recovered_img).reshape(266, 256))\n",
    "axs[0].set_title('recovered img')\n",
    "axs[1].imshow(pca.inverse_transform(sample_img).reshape(266, 256))\n",
    "axs[1].set_title('original img')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
